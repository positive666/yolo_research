
<div align='left'>
  <img src=https://img.shields.io/github/stars/positive666/yolo_research.svg?style=social >
  <img src=https://img.shields.io/github/forks/positive666/yolo_research.svg?style=social >
  <img src=https://img.shields.io/github/watchers/positive666/yolo_research.svg?style=social>
</div> 


<!-- <div align="center">
<p>
   <a align="left" href="https://github.com/positive666/yolo_research" target="_blank">
   <img src="./data/images/yolov.jpg" width="87%"></a>
</p>
</div> -->



##  <div align="left">ğŸš€ yolo_reserach PLUS High-level</div>

ğŸš€ğŸš€ğŸš€æ‹›å‹Ÿï¼šå¯»çƒ­çˆ±ç®—æ³•ç ”å‘çš„å°ä¼™ä¼´å…±åŒå¼€å‘å’Œç»´æŠ¤å¼€æºé¡¹ç›®ï¼Œæ·»åŠ IDEAï¼Œç”šè‡³å¤šæ¨¡æ€é¢†åŸŸåº”ç”¨ä¹Ÿå¯ï¼Œæœ‰æˆæœä¸å»ºè®®è‡ªå·±å¸¦èµ°ï¼Œå·¥ç¨‹ä¸Šæˆ‘æ¥ç»´æŠ¤ï¼Œéœ€è¦ä¸€å®šçš„ç®—æ³•ç ”å‘èƒŒæ™¯å’Œèƒ½åŠ›ï¼Œè”ç³»å¯é¦–é¡µé‚®ç®±ã€‚
æ›´æ–°å‡çº§ä¸­.. Add latest V8 core yolov8è§£æï¼šhttps://blog.csdn.net/weixin_44119362/article/details/129417459 ,ï¼ˆå·¥ä½œç¹å¿™ï¼Œä¼šä¸æ–­æ›´æ–°ä¼˜åŒ–ï¼Œæœ‰é—®é¢˜æŒ‚issueï¼‰

### <div align="left">â­æ–°é—»æ¿å—ã€å®æ—¶æ›´æ–°ç‰ˆå—ã€‘</div>

	- 2023/4/6  ä»2021å¹´åˆ°2023å¹´ï¼Œå³ä½¿ä¸åšæ£€æµ‹ï¼Œä¾ç„¶åšæŒæ›´æ–°ï¼Œæ¬ç –ä¸æ˜“ï¼Œåç»­ä¼šæœ‰æ›´å¤šæ›´æ–°,ä½†æ˜¯ç›®å‰å…ˆé›†æˆç¨³å®šå„ä¸ªåŠŸèƒ½ä¸ºä¸»ï¼šæ›´æ–°v8çš„poseæ¨¡å—ï¼Œæ”¯æŒv8ä»£ç è®­ç»ƒè‡ªå®šä¹‰çš„ç½‘ç»œç»“æ„å¹¶åŠ è½½æƒé‡è®­ç»ƒï¼›ä¹‹å‰çš„é—®é¢˜ä½œä¸ªç®€å•è§£é‡Šï¼šå°±æ˜¯åœ¨å®‰è£…æºç ç¯å¢ƒåå…¶å®åªæ˜¯æ”¯æŒä½ è§£æå®˜æ–¹çš„é¢„è®­ç»ƒæƒé‡ï¼Œå¦‚æœä½ ç”¨æœ¬é¡¹ç›®çš„ä»£ç è®­ç»ƒå,å¯ä»¥å¸è½½æ‰æºç ç¯å¢ƒï¼Œç»§ç»­æ›´æ–°ä¸­
	- 2023/3/28 åŒæ­¥å…¼å®¹æœ€æ–°çš„V8ä»£ç æ›´æ–°ï¼šç›®å‰V8ä¾èµ–äºpip install ultralytics,æˆ‘åœ¨ä»£ç æ›´æ–°ä¸­ä¹Ÿå‘ç°äº†è¯¥é—®é¢˜ï¼Œè™½ç„¶æœ¬é¡¹ç›®åšäº†åˆ†ç¦»ï¼Œä½†æ˜¯ä½¿ç”¨å®˜æ–¹æƒé‡ä½œä¸ºé¢„è®­ç»ƒæƒé‡å»åŠ è½½çš„å‰æä¸‹ï¼šä»ç„¶éœ€è¦ä¾èµ–ä¸­çš„ultralytics.nnæ–‡ä»¶å¤¹ï¼Œä¸ç„¶å¯èƒ½ä¼šæŠ¥é”™ï¼Œå› ä¸ºæ˜¯è¿™æ ·çš„æœ¬é¡¹ç›®æ”¹äº†æ¨¡å‹å±‚çš„å‚æ•°åå­—ï¼Œå› ä¸ºV8æ¯å±‚çš„åå­—æ˜¯å¸¦â€œultralytics.nn â€çš„ï¼Œå¦‚æœä¸å®‰è£…è¿™ä¸ªéƒ¨åˆ†ä»£ç ï¼Œä½ torchæ‰“ä¸å¼€V8å®˜æ–¹çš„æƒé‡ï¼Œæ•…ç›®å‰ä¸¤ç§è§£å†³åŠæ³•ï¼š1.scratch 2.pipå®‰è£…åæ‰“å¼€å°†æƒé‡åå­—é‡æ„ 3.ä»£ç ç›®å½•ä¿®æ”¹ åç»­æˆ‘ä¼šä¼˜åŒ–è§£å†³ï¼Œä¸è¿‡ç›®å‰é¡¹ç›®ä¸­çš„å·¥ä½œå¤ªå¤šäº†ï¼Œæ•…å¦‚æœå‡ºç°æŠ¥é”™è¿˜æ˜¯ä½¿ç”¨ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼špip install ultralytics,è¿™æ ·æ¯”è¾ƒç®€å•ç›´æ¥å…¼å®¹ï¼Œç„¶åå¯ä»¥è¿è¡Œã€€python train_v8.py ï¼Œæœªè§£å†³çš„å°±æ˜¯å¦‚æœè‡ªå®šä¹‰æœºæ„å¯èƒ½æ— æ³•ç›´æ¥åŠ è½½å®˜æ–¹çš„æƒé‡ï¼Œæ±‡åç»­è§£å†³ï¼  
	- 2023/3/1  add v8 core:æ˜¥èŠ‚æœŸé—´çœ‹äº†ä¸‹V8ï¼Œç”±äºè¿‘åŠå¹´é¡¹ç›®æ¯”è¾ƒå¤šä¹Ÿæ˜¯è€½è¯¯äº†å¥½ä¹…(åŸç‰ˆæœ¬æ˜¯å°†V8çš„æ‰€æœ‰åŠŸèƒ½å…¨éƒ¨èåˆåˆ°äº†V5çš„ä»£ç ä¸­ï¼Œå’ŒV8å‘½ä»¤ä¸€æ ·ï¼Œä½†æ˜¯è®­ç»ƒçš„æ—¶å€™å‘ç”Ÿäº†é—®é¢˜ï¼Œæ’æŸ¥å‘ç°é—®é¢˜å‘ç”Ÿåœ¨V5çš„æ•°æ®è¯»å–å¤„ç†ï¼Œæ‰€ä»¥æš‚æ—¶ä½¿ç”¨V8çš„è®­ç»ƒç»“æ„ä»£ç ï¼Œä¹Ÿä¾¿äºåŒºåˆ†)ï¼Œç„¶åæŠ“ç´§æ—¶é—´ä¸åœæ›´æ–°ï¼›
	- 2022/11/23 ä¿®å¤å·²çŸ¥BUGï¼ŒV7.0ç‰ˆæœ¬æ›´æ–°å…¼å®¹ï¼Œå¹´åº•æ¯”è¾ƒå¿™åç»­å¿™å®Œä¸šåŠ¡ä¼šå¤§æ›´æ–°
	- 2022/10/20 ä¿®å¤é€‚é…V7ç»“æ„å’Œé¢å¤–ä»»åŠ¡å¼•èµ·çš„ä¸€äº›ä»£ç é—®é¢˜ï¼Œå®æ—¶æ›´æ–°V5çš„ä»£ç ä¼˜åŒ–éƒ¨åˆ†ï¼Œæ·»åŠ äº†å·¥å…·grad_camåœ¨toolsç›®å½•ã€‚
	- 2022/9/19 ä¿®å¤å·²çŸ¥BUGï¼Œæ›´æ–°äº†å®æ—¶çš„V5BUGä¿®å¤å’Œä»£ç ä¼˜åŒ–èåˆéªŒè¯ï¼Œæ ¸å¿ƒæ£€æµ‹ã€åˆ†ç±»ã€åˆ†å‰²çš„éƒ¨åˆ†CIéªŒè¯ï¼Œå…³é”®ç‚¹æ£€æµ‹å®æµ‹è®­ç»ƒæ­£å¸¸ï¼ŒåŸºæœ¬åŠŸèƒ½æ•´ç†å®Œæ¯•ã€‚
	- 2022/9/15 åˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ã€å…³é”®ç‚¹æ£€æµ‹åŸºæœ¬æ•´åˆå®Œæ¯•ï¼Œå·¥ç¨‹ç»“æ„ç²¾ç®€åŒ–ä¸­ï¼Œå…³é”®ç‚¹æ£€æµ‹è®­ç»ƒæ­£å¸¸å·²ç»éªŒè¯ï¼Œåˆ†å‰²å¾…è°ƒè¯•ï¼Œç«é€Ÿè¿­ä»£ä¸­
	- åˆ†å‰²ä»£ç ç»“åˆV5å’ŒV7çš„ä»£ç è¿›è¡Œäº†åˆå¹¶DEBUGè°ƒè¯•ï¼Œè®­ç»ƒéƒ¨åˆ†å¾…éªŒè¯ï¼Œå¦å¤–æ³¨æ„åŠ›å±‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ²¡æ³•æ”¶æ•›æˆ–è€…NANçš„æƒ…å†µï¼Œæ’é™¤ä»£ç é—®é¢˜ï¼Œéœ€è¦åœ¨è¶…å‚æ•°YAMLé‡Œï¼Œå…ˆå¯¹å­¦ä¹ è¡°å‡ç‡ä»æ”¹ä¸º0.2 ï¼Œæ¯”å¦‚GAMçš„æ³¨æ„åŠ›å¤´éƒ¨é—®é¢˜ï¼Œè®­ç»ƒå‘¨æœŸåŠ åˆ°400epoch+ å°±å¯ä»¥ã€‚
	- å»å¹´çš„decoupledç»“æ„è™½ç„¶èƒ½æç‚¹ï¼Œä¸è¿‡FLOPSå¢åŠ çš„å¤ªå¤šï¼Œç›®å‰ç”¨V5ä½œè€…åˆ†æ”¯çš„è§£è€¦å¤´æ›¿æ¢ï¼Œæ•ˆæœå¾…éªŒè¯ã€‚
	- èåˆäº†ä»£ç åšäº†éƒ¨åˆ†çš„ä¼˜åŒ–ï¼Œè¿™é‡Œçœ‹äº†ä¸‹V7çš„ä»£ç ä¼˜åŒ–è¾ƒå·®ï¼Œåç»­ä¼šé›†æˆç²¾ç®€ç‰ˆæœ¬çš„åˆ†ç±»ã€åˆ†å‰²ã€æ£€æµ‹ã€POSEæ£€æµ‹çš„ç»“æ„ï¼Œç›®å‰å·²ç»å®Œæˆäº†ä¸€éƒ¨åˆ†å·¥ä½œï¼Œæ›´æ–°é¢‘ç¹æœ‰é—®é¢˜æ¬¢è¿åé¦ˆå’Œæä¾›å®éªŒç»“æœã€‚
<p>

å…³äºè¿™ä¸ªé¡¹ç›®çš„ä½¿ç”¨è¯´æ˜è¯¦è¯·å¯å‚è€ƒä¸‹é¢åšå®¢ï¼š
[csdnæŒç»­æ›´æ–°2021-2022å¹´](https://blog.csdn.net/weixin_44119362/article/details/126895964?spm=1001.2014.3001.5501) ,[csdnæŒç»­æ›´æ–°2023å¹´](https://blog.csdn.net/weixin_44119362/article/details/129417459?spm=1001.2014.3001.5502)

<details >
<summary>å½“å‰ Project ç»“æ„è¯´æ˜</summary>


```
yolo_research
â”‚   pose  
â”‚   â””â”€â”€â”€â”€â”€   ## å…³é”®ç‚¹æ£€æµ‹ä»»åŠ¡ä½¿ç”¨
â”‚   ...    
â”‚   models   ## å­˜å‚¨æ¨¡å‹ï¼šç®—å­å®šä¹‰å’Œæ‰€æœ‰æ¨¡å‹çš„yamlç»“æ„å®šä¹‰ï¼ŒåŒ…å«yolov5\yolov7\yolov8  

    â””â”€â”€â”€â”€â”€   common.py   æ¨¡å‹ç®—å­å®šä¹‰
             yolo.py     æ¨¡å‹ç»“æ„å®šä¹‰
â”‚   â””â”€â”€â”€â”€â”€   cls         åˆ†ç±»æ¨¡å‹ç»“æ„
â”‚            pose        å…³é”®ç‚¹æ¨¡å‹ç»“æ„
â”‚            segment     åˆ†å‰²æ¨¡å‹ç»“æ„
â”‚            detect  v5u_cfg/v7_cfg/v8_cfg    æ£€æµ‹æ¨¡å‹ç»“æ„..å…¶ä½™æ˜¯V5ç‰ˆæœ¬ä»¥åŠä¸€äº›æ”¹çš„å‚è€ƒç¤ºä¾‹      
â”‚   ....
â”‚   segment
â”‚   â””â”€â”€â”€â”€â”€   ## åˆ†å‰²ä»»åŠ¡
|   classify
â”‚   â””â”€â”€â”€â”€â”€   ## åˆ†ç±»ä»»åŠ¡
|   tracker
â”‚   â””â”€â”€â”€â”€â”€   ## è·Ÿè¸ªä»»åŠ¡ Fork V8
â”‚   utils
â”‚   â””â”€â”€â”€â”€â”€   #é€šç”¨éƒ¨åˆ†ä»£ç 
|          .
|          .
|            segment   ##åˆ†å‰²çš„æ•°æ®å¤„ç†æ“ä½œéƒ¨åˆ†
|   yolo
â”‚   â””â”€â”€â”€â”€â”€   v8        ## yolov8 core ,ä¸»è¦åŒ…å«è®­ç»ƒéƒ¨åˆ†å’Œæ¨ç†ä½¿ç”¨éƒ¨åˆ†çš„ç›¸å…³ä»£ç 
â”‚             â””â”€â”€â”€â”€â”€ .
|            cfg       ## default.yaml è®¾ç½®æ‰€æœ‰V8ç›¸å…³å‚æ•°
|            engine    ## å®šä¹‰åŸºç±»ç»“æ„
|            utils
|            data
|               .
|               .
|       .
|       .    ##å…¶ä½™ä¸ºæ£€æµ‹æ ¸å¿ƒä»£ç å’Œé€šç”¨éƒ¨åˆ†
```

</details>

# Feature ğŸš€ 
    
     - æœ€æ–°çš„yoloV5å·¥ç¨‹é£æ ¼ä»£ç èåˆï¼Œæ”¯æŒè‡ªç”±å®šä¹‰æ­é…æ‰€æœ‰ç»„ä»¶ï¼ŒåŠ å…¥V8éƒ¨åˆ†,å…¼å®¹äº†anchor-freeçš„yolov8ï¼Œé’ˆå¯¹High-levelä»»åŠ¡ï¼šå®Œæˆå…ˆè¿›çš„æ£€æµ‹å™¨ã€è·Ÿè¸ªå™¨ã€åˆ†ç±»å™¨ã€åˆ†å‰²ã€å…³é”®ç‚¹æ£€æµ‹åŠŸèƒ½ä»»åŠ¡é›†æˆï¼Œé€æ­¥åˆ é™¤é¢å¤–åº“ä¾èµ–
     
     - å®æ—¶çš„v5ä»£ç æ›´æ–°æ”¹åŠ¨&&v7ç­‰workçš„ç»“æ„é€‚é…ï¼ˆæ¯å‘¨åŒæ­¥yolov5çš„ä»£ç ä¼˜åŒ–ï¼‰
     
     - æ—©æœŸé›†æˆçš„attentionã€self-attentionç»´æŠ¤å’Œè°ƒè¯•
     
     - é¢å¤–çš„ç½‘ç»œç»“æ„å’ŒTricksè¡¥å……
    	
     - deepstreaméƒ¨ç½²å·¥ç¨‹ï¼ˆä»…é™Linuxå¹³å°:ç›®å‰gitä¸Šæ˜¯21å¹´å¼€æºçš„5.1ç‰ˆæœ¬ï¼Œåç»­å¦‚æœæœ‰ç©ºæ•´ç†å¥½è¯´æ˜ä¸Šä¼ 6.xxxçš„ç‰ˆæœ¬ï¼‰

<details >
<summary>å…³äºæ¨¡å‹ä¿®æ”¹å’Œè®¾è®¡</summary>

     - 2021å¹´åœ¨CSDNä¸­ä»‹ç»è¿‡ä¸€äº›èŒƒå¼ç¤ºä¾‹åŒ…å«æ³¨æ„åŠ›ã€è‡ªæ³¨æ„åŠ›å±‚ç­‰æœºåˆ¶æ—©æœŸå¼•å…¥äº†ä¸€äº›æ¯”è¾ƒæœ‰çƒ­åº¦çš„ä¿®æ”¹ï¼Œå…¶å®åœ¨å¦‚ä»Šå›¾åƒåŸºç¡€ä»»åŠ¡è¡¨ç°é‡Œï¼ŒCNNå’Œtransformerå¹¶ä¸æ²¡æœ‰æ˜æ˜¾å·®è·ï¼Œä¸ªäººè§‰å¾—ä½œä¸ºå­¦ä¹ ç§¯ç´¯å°±å¥½ã€‚æ¯”å¦‚swinv1å’Œv2ç­‰ä¸€äº›å½“æ—¶æµè¡Œçš„è®ºæ–‡ç½‘ç»œç»„ä»¶ï¼Œä»¥åŠåŒæ ·çš„NECKã€HEADã€LOSSçš„æ·»åŠ ï¼Œä½ å¯ä»¥å‚è€ƒgithubé¡¹ç›®ä¸­çš„yamlç»“æ„ç¤ºä¾‹å»è‡ªå·±å°è¯•ä¿®æ”¹æ¨¡å‹ï¼Œå°±æ˜¯å¸Œæœ›å¤§å®¶èƒ½å¤Ÿå¤šæ€è€ƒå¤šç§¯ç´¯ä¸”è‡ªå·±åŠ¨æ‰‹å®ç°ï¼Œä¹Ÿæ˜¯æˆ‘å½“åˆæ–‡ç« çš„æœ¬æ„ï¼Œè€Œä¸æ˜¯åªé™äºä¸€ç§èŒƒå¼æˆ–å‡ ç§ç»“æ„ï¼Œå¦‚æœé‡åˆ°é—®é¢˜æ¬¢è¿åˆ†äº«è®¨è®ºï¼Œå…·ä½“å¯ä»¥çœ‹åšå®¢ä¸­çš„[ä¿®æ”¹å»ºè®®](https://editor.csdn.net/md/?articleId=126895964ï¼‰

     - å¯¹äºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ä½¿ç”¨ï¼šå¾ˆå¤šäººä¸CNNç›¸ç»“åˆä½¿ç”¨å¾—åˆ°ç²¾åº¦æå‡ï¼Œä¸ªäººç†è§£ï¼šåŸå› ä¸ä»…ä»…æ˜¯é•¿è·ç¦»çš„ä¾èµ–ï¼Œæ—©æœŸæˆ‘ä»¬ä½¿ç”¨å›ºå®šæƒé‡çš„æ»¤æ³¢å™¨æå–è¾¹ç¼˜å†åˆ°CNNï¼ŒCNNä¹Ÿè®¸æ˜¯å¯¹åº”ç€é«˜é€šæ»¤æ³¢ï¼Œè€Œself-attentionå¯¹åº”äºä½é€šæ»¤æ³¢ï¼Œé‚£ä¹ˆç›¸å½“äºå¯¹featuremapè¿›è¡Œäº†ä¸€æ¬¡å¹³æ»‘ï¼Œè¿™æ ·ä»æŸç§ç¨‹åº¦ä¸Šå¯ä»¥è§£é‡Šäº’è¡¥ä¹‹åçš„æå‡ï¼›è€Œä¸”transfromeræ˜¯å¾ˆéš¾å‘ç”Ÿè¿‡æ‹Ÿåˆæˆ–è€…è¯´ä¸å­˜åœ¨ï¼ŒåŒæ—¶ç”±äºå¢é‡çˆ†ç‚¸å’Œå·¥ç¨‹å¼€å‘çš„ç°è±¡ï¼Œä½¿å¾—å…¶å¹¶ä¸å¥½è®­ç»ƒï¼Œä½†æ˜¯åŠ¨æ€ç‰¹æ€§ç¡®å®æ›´å…·æ³›åŒ–æ€§ï¼Œå¸¸è§„æƒ…å†µä¸­ä¼˜å…ˆè€ƒè™‘ä½ è®­ç»ƒæ•°æ®é›†çš„æ‹Ÿåˆå¤Ÿä¸å¤Ÿå¥½ï¼Œä½ çš„æ¨¡å‹æ˜¯å¦èƒ½åæ˜ å‡ºæ•°æ®ä¹‹é—´çš„ç‰¹å¾ç‰¹å¼‚æ€§ï¼Œå…¶æ¬¡æ‰©å……æ„å»ºç›¸åº”çš„è¾…åŠ©åˆ†æ”¯åŠ å…¥ç‰¹å¾å±æ€§æè¿°ã€‚

</details>

[CSDNåŒæ­¥æ›´æ–°ï¼Œä¸»é¡µå¯æŒ‰å…´è¶£åŸåˆ›æ–‡ç« ç‚¹å‡»](https://blog.csdn.net/weixin_44119362?type=blog)
(ä¿è¯æ¯å‘¨åŒæ­¥æ›´æ–°ä¸€æ¬¡ç»´æŠ¤ï¼Œä¸å®šæœŸæ›´æ–°ç®—æ³•ä»£ç å’Œå¼•è¿›ç»“æœå®éªŒï¼å…³äºæ¶ˆèå®éªŒå¤§å¤šæ¥è‡ªæœ‹å‹çš„çƒ­å¿ƒåé¦ˆï¼Œæ¢ç©¶èŒƒå¼CNNå’Œtransformerï¼Œå¦‚ä½•æ ¹æ®ç»éªŒè®¾è®¡ç½‘ç»œç»“æ„ã€LOSSæ”¹è¿›ã€è¾…åŠ©è®­ç»ƒåˆ†æ”¯ã€æ ·æœ¬åŒ¹é…....  æ¬¢è¿æä¾›å®éªŒæ•°æ®å’Œçµæœ~)




<details open>
<summary>Install</summary>
Clone repo and install [requirements.txt](https://github.com/positive666/yolo_research/requirements.txt) 

```bash
git clone https://github.com/positive666/yolo_research  # clone
cd yolov5_research
pip install -r requirements.txt  # install
```

</details>

<details open>
<summary>YOLOV8 install in conda env  and  offical command</summary>

pip install ultralytics 

if you pip install ultralytics,you can run offical command 
```bash
yolo task=detect    mode=train   data=<data.yaml path>      model=yolov8n.pt        args...
          classify       predict        coco-128.yaml       yolov8n-cls.yaml  args...
          segment        val                                yolov8n-seg.yaml  args...
                         export                             yolov8n.pt        format=onnx  args...
```
ps: if your model=*.yaml -->scratch else use pretrained models
python command :


if use this repo ,you need set your data and model path in cfg/default.yaml

```bash
    
    python yolo\v8\detect\train.py  --<args>

```

æ¨ç†éƒ¨åˆ†å’ŒV5ã€V8çš„ä»£ç å…¼å®¹
</details>  

<details>
<summary>Multi-GPU DistributedDataParallel </summary>
ä½¿ç”¨DistributedDataParallelï¼Œå¤šä¸ªè¿›ç¨‹åªè¿›è¡Œå€’æ•°ä¼ æ’­ï¼Œæ¯ä¸ªGPUéƒ½è¿›è¡Œä¸€æ¬¡æ¢¯åº¦æ±‚å¯¼å’Œå‚æ•°æ›´æ–°ï¼Œè¿™æ¯”DataParallelçš„æ–¹å¼æ›´é«˜æ•ˆï¼Œå› ä¸ºDataParalledlåªæœ‰ä¸€ä¸ªä¸»GPUè¿›è¡Œå‚æ•°æ›´æ–°ï¼Œæ‰€ä»¥éœ€è¦å„ä¸ªå­è¿›ç¨‹è°ƒç”¨çš„GPUä¼ é€’å€’æ•°åˆ°ä¸»GPUåï¼Œæ‰ä¼šæ›´æ–°å‚æ•°çµ¦å„ä¸ªGPUï¼Œæ‰€ä»¥è¿™ä¼šæ¯”DistributedDataParallelæ¯ä¸ªGPUç›´æ¥è¿›è¡Œå‚æ•°æ›´æ–°è¦æ…¢å¾ˆå¤šã€‚ â€“nproc_per_node: ä½œä¸ºGPUçš„ä½¿ç”¨æ•°é‡èŠ‚ç‚¹æ•° â€“batchï¼šæ€»batch-size ,ç„¶åé™¤ä»¥Nodeæ•°é‡ ï¼Œå¹³å‡ç»™æ¯ä¸ªGPUã€‚
```bash
python -m torch.distributed.run --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s.pt --device 0,1
```
</details>  

<details>
<summary>Multi -machines && Multi-GPU </summary>
```bash
ä¸»æœº
python -m torch.distributed.run --nproc_per_node G --nnodes N --node_rank 0 --master_addr "192.168.1.1" --master_port 1234 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights ''
#å¤šä¸ªå‰¯æœº
python -m torch.distributed.run --nproc_per_node G --nnodes N --node_rank R --master_addr "192.168.1.1" --master_port 1234 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights ''
```
â€“master_portï¼šç«¯å£å·
master_addrï¼šä¸»è¿›ç¨‹ipåœ°å€
G:æ¯ä¸ªæœºå™¨çš„GPUæ•°é‡
N:æœºå™¨æ•°é‡
R:å­æœºå™¨åºå·

</details>  


## <div align="center">ç›®æ ‡æ£€æµ‹ç¯‡</div>

<details>
<summary>Inference with detect.py</summary>


```bash
python detect.py --source 0  # webcam     --weights <your model weight>
                          img.jpg  # image
                          vid.mp4  # video
                          path/  # directory
                          'path/*.jpg'  # glob
                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```
</details>  

yolov7 å®˜æ–¹çš„è¨“ç·´æƒé‡æ‰“åŒ…é“¾æ¥ï¼šhttps://pan.baidu.com/s/1UIYzEZqTPMUpWWBBczOcgA?pwd=v7v7(ç”±äºæˆ‘åˆ é™¤äº†P6æ¨¡å‹é‡Œçš„Reorgæ“ä½œå’ŒFocusæ²¡æœ¬è´¨åŒºåˆ«ï¼Œæ‰€ä»¥åˆ æ‰éœ€è¦é‡æ–°è®­ç»ƒï¼Œå¦‚æœä½ æƒ³ä½¿ç”¨V7åŸå§‹æƒé‡ï¼Œä½ åªéœ€è¦åœ¨YAMLé‡Œæ”¹å›å»ï¼Œè¿˜æœ‰ä¸€ç§æ–¹å¼æ˜¯éå†Reorgçš„æƒé‡æŠŠå®ƒæ›¿æ¢æ‰) æå–ç ï¼šv7v7

###  Train

see train.py args ,command as :


```bash
python train.py --data <your data yaml>  --cfg  <your model yaml> --weights <weights path>  --batch-size 128    --hyp   <hyps yaml>  --batch-size <numbers>  
```
<details open>
<summary>Notes</summary>

- "--swin_float"  for "SwinTransformer_Layer" layers,because of " @" not support  fp16,so you can use offical yolov7 â€œ Swinv2Blockâ€
- "--aux_ota_loss" for aux- head only . Such "models/detect/v7_cfg/training/yolov7x6x.yaml, (P6-model) ,you can create aux -head models.		
- "ota_loss"  in hyps filse ,ota_loss default=0 
</details>   

<details>
<summary>Training commnd example </summary>

-  run yolov7-P5 model train and yolov5 seriese models ,scratch or fine ,your need a weights 

```bash 
python train.py  --data data/coco128.yaml  --cfg models/detect/yolov5s_decoupled.yaml   
```
```bash 
python train.py  --cfg  models/detect/v7_cfg/training/yolov7.yaml  --weights yolov7.pt  --data (custom datasets) --hyp data/hyps/hyp.scratch-v7.custom.yaml	
```
-  run yolov7-aux model train ,your model must P6-model !
```bash 
python train.py  --cfg  models/detect/v7_cfg/training/yolov7w6.yaml --imgsz 1280  --weights 'yolov7-w6_training.pt'  --data (custom datasets)  --aux_ota_loss  --hyp data/hyps/hyp.scratch-v7.custom.yaml
```
- After training/under yaml structure, your initial weight xxx. PT will become a trained yolov7xxx.pt , with specific references to reparameterized scripts. 
Then use the deploy model to load the weights of your training, change the index and structure to re-parameterize the model.

</details>

<details open>
<summary>re-parameterizetrained yolov7 model  </summary>

```bash 
   python reparameterization.py  --weights <yolov7.pt,yolov7e6e.pt.....>  --name <model name > --save_file   models/v7_cfg/deploy  --cfg <model.yaml>
```
</details>

/details>

<details >
<summary>Offical Model Zoo </summary>

| Model                                                                                | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>A100 TensorRT<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |
| ------------------------------------------------------------------------------------ | --------------------- | -------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |
| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640                   | 37.3                 | 80.4                           | 0.99                                | 3.2                | 8.7               |
| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt) | 640                   | 44.9                 | 128.4                          | 1.20                                | 11.2               | 28.6              |
| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt) | 640                   | 50.2                 | 234.7                          | 1.83                                | 25.9               | 78.9              |
| [YOLOv8l](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt) | 640                   | 52.9                 | 375.2                          | 2.39                                | 43.7               | 165.2             |
| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640                   | 53.9                 | 479.1                          | 3.53                                | 68.2               | 257.8             |

</details>

##  <div align="center">å…³é”®ç‚¹æ£€æµ‹ç¯‡</div>

<details>
<summary>æ•°æ®é›†æ„å»º</summary>

```
yolov5_research
â”‚   pose  
â”‚   â””â”€â”€â”€â”€â”€(key point detect code )
â”‚   ...   
â”‚
coco_kpts(your data yaml path name )
â”‚   images
â”‚   annotations/**.json
|   labels
â”‚   â””â”€â”€â”€â”€â”€train2017
â”‚       â”‚       â””â”€â”€â”€
|       |       â””â”€â”€â”€
|       |       '
|       |       .
â”‚       â””â”€val2017
|               â””â”€â”€â”€
|               â””â”€â”€â”€
|               .
|               .
|    train2017.txt
|    val2017.txt

```
</details>

###  Inference
refernce v7 weights.
[yolov7-w6-pose.pt](https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt)

``` bash 
python pose/detect.py --weights pose/pose_weights/yolov7-w6-pose.pt  --source  data/images/bus.jpg   --kpt-label 
```
###  Train

[yolov7-w6-person.pt](https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-person.pt)

``` shell
    python pose/train.py --data  data/coco_kpts.yaml  --cfg  pose/cfg/yolov7-w6-pose.yaml weights yolov7-w6-person.pt --img 960  --kpt-label --hyp data/hyps/hyp.pose.yaml

```

##  <div align="center">åˆ†å‰²ç¯‡</div>

###  Inference

``` bash 
python segment/predict.py --weights yolov5s-seg.pt --source 0                          
```

###  Train
``` bash 
python segment/train.py --data coco128-seg.yaml --weights yolov5s-seg.pt --img 640  # from pretrained (recommended)
```


##  <div align="center">åˆ†ç±»ç¯‡yolov5å®˜æ–¹ç‰ˆæœ¬</div>
YOLOv5 [release v6.2](https://github.com/ultralytics/yolov5/releases) brings support for classification model training, validation, prediction and export! We've made training classifier models super simple. Click below to get started.

<details>
  <summary>Classification Checkpoints (click to expand)</summary>

<br>

We trained YOLOv5-cls classification models on ImageNet for 90 epochs using a 4xA100 instance, and we trained ResNet and EfficientNet models alongside with the same default training settings to compare. We exported all models to ONNX FP32 for CPU speed tests and to TensorRT FP16 for GPU speed tests. We ran all speed tests on Google [Colab Pro](https://colab.research.google.com/signup) for easy reproducibility.

| Offcial Model Zoo                                                                                  | size<br><sup>(pixels) | acc<br><sup>top1 | acc<br><sup>top5 | Training<br><sup>90 epochs<br>4xA100 (hours) | Speed<br><sup>ONNX CPU<br>(ms) | Speed<br><sup>TensorRT V100<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>@224 (B) |
|----------------------------------------------------------------------------------------------------|-----------------------|------------------|------------------|----------------------------------------------|--------------------------------|-------------------------------------|--------------------|------------------------|
| [YOLOv5n-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n-cls.pt)         | 224                   | 64.6             | 85.4             | 7:59                                         | **3.3**                        | **0.5**                             | **2.5**            | **0.5**                |
| [YOLOv5s-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s-cls.pt)         | 224                   | 71.5             | 90.2             | 8:09                                         | 6.6                            | 0.6                                 | 5.4                | 1.4                    |
| [YOLOv5m-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m-cls.pt)         | 224                   | 75.9             | 92.9             | 10:06                                        | 15.5                           | 0.9                                 | 12.9               | 3.9                    |
| [YOLOv5l-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l-cls.pt)         | 224                   | 78.0             | 94.0             | 11:56                                        | 26.9                           | 1.4                                 | 26.5               | 8.5                    |
| [YOLOv5x-cls](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x-cls.pt)         | 224                   | **79.0**         | **94.4**         | 15:04                                        | 54.3                           | 1.8                                 | 48.1               | 15.9                   |
|                                                                                                    |
| [ResNet18](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet18.pt)               | 224                   | 70.3             | 89.5             | **6:47**                                     | 11.2                           | 0.5                                 | 11.7               | 3.7                    |
| [ResNet34](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet34.pt)               | 224                   | 73.9             | 91.8             | 8:33                                         | 20.6                           | 0.9                                 | 21.8               | 7.4                    |
| [ResNet50](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet50.pt)               | 224                   | 76.8             | 93.4             | 11:10                                        | 23.4                           | 1.0                                 | 25.6               | 8.5                    |
| [ResNet101](https://github.com/ultralytics/yolov5/releases/download/v6.2/resnet101.pt)             | 224                   | 78.5             | 94.3             | 17:10                                        | 42.1                           | 1.9                                 | 44.5               | 15.9                   |
|                                                                                                    |
| [EfficientNet_b0](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b0.pt) | 224                   | 75.1             | 92.4             | 13:03                                        | 12.5                           | 1.3                                 | 5.3                | 1.0                    |
| [EfficientNet_b1](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b1.pt) | 224                   | 76.4             | 93.2             | 17:04                                        | 14.9                           | 1.6                                 | 7.8                | 1.5                    |
| [EfficientNet_b2](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b2.pt) | 224                   | 76.6             | 93.4             | 17:10                                        | 15.9                           | 1.6                                 | 9.1                | 1.7                    |
| [EfficientNet_b3](https://github.com/ultralytics/yolov5/releases/download/v6.2/efficientnet_b3.pt) | 224                   | 77.7             | 94.0             | 19:19                                        | 18.9                           | 1.9                                 | 12.2               | 2.4                    |

<details>
  <summary>Table Notes (click to expand)</summary>

- All checkpoints are trained to 90 epochs with SGD optimizer with `lr0=0.001` and `weight_decay=5e-5` at image size 224 and all default settings.<br>Runs logged to https://wandb.ai/glenn-jocher/YOLOv5-Classifier-v6-2
- **Accuracy** values are for single-model single-scale on [ImageNet-1k](https://www.image-net.org/index.php) dataset.<br>Reproduce by `python classify/val.py --data ../datasets/imagenet --img 224`
- **Speed** averaged over 100 inference images using a Google [Colab Pro](https://colab.research.google.com/signup) V100 High-RAM instance.<br>Reproduce by `python classify/val.py --data ../datasets/imagenet --img 224 --batch 1`
- **Export** to ONNX at FP32 and TensorRT at FP16 done with `export.py`. <br>Reproduce by `python export.py --weights yolov5s-cls.pt --include engine onnx --imgsz 224`
</details>
</details>

<details>
  <summary>Classification Usage Examples (click to expand)</summary>

### Train
YOLOv5 classification training supports auto-download of MNIST, Fashion-MNIST, CIFAR10, CIFAR100, Imagenette, Imagewoof, and ImageNet datasets with the `--data` argument. To start training on MNIST for example use `--data mnist`.

```bash
# Single-GPU
python classify/train.py --model yolov5s-cls.pt --data cifar100 --epochs 5 --img 224 --batch 128

# Multi-GPU DDP
python -m torch.distributed.run --nproc_per_node 4 --master_port 1 classify/train.py --model yolov5s-cls.pt --data imagenet --epochs 5 --img 224 --device 0,1,2,3
```

### Val
Validate YOLOv5m-cls accuracy on ImageNet-1k dataset:
```bash
bash data/scripts/get_imagenet.sh --val  # download ImageNet val split (6.3G, 50000 images)
python classify/val.py --weights yolov5m-cls.pt --data ../datasets/imagenet --img 224  # validate
```

### Predict
Use pretrained YOLOv5s-cls.pt to predict bus.jpg:
```bash
python classify/predict.py --weights yolov5s-cls.pt --data data/images/bus.jpg
```
```python
model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s-cls.pt')  # load from PyTorch Hub
```

### Export
Export a group of trained YOLOv5s-cls, ResNet and EfficientNet models to ONNX and TensorRT:
```bash
python export.py --weights yolov5s-cls.pt resnet50.pt efficientnet_b0.pt --include onnx engine --img 224
```
</details>

##  <div align="center">å†å²æ›´æ–°</div>

<details>
<summary>æ›´æ–°è®°å½•</summary>
- 2020/9/15  High-level é›†æˆå¾…éªŒè¯ï¼Œç›®å‰å§¿æ€è®­ç»ƒå’Œæ£€æµ‹å·²ç»è°ƒè¯•å®Œæˆã€‚
- 2022/7/21  é™¤å…³é”®ç‚¹éƒ¨åˆ†çš„V7ä»£ç ä»¥åŠV5ä»£ç é£æ ¼ä¼˜åŒ–åˆå¹¶æ›´æ–°ï¼Œæ”¹å–„äº†é‡å‚æ•°è„šæœ¬çš„åŠŸèƒ½ï¼Œè¯¦æƒ…çœ‹	reparameterization.py

- 2022/7/13  åŒæ­¥æ›´æ–°åŠ å…¥äº†yolov7çš„P6æ¨¡å‹è¨“ç·´éƒ¨åˆ†ä»£ç¢¼ï¼Œp6æ˜¯éœ€è¦auxçš„æ‰€ä»¥éœ€è¦æ·»åŠ Losséƒ¨åˆ†è¨ˆç®—ï¼Œä»£ç¢¼å’ŒCSDNæŒçºŒæ›´æ–°ä¸­,ç”±äºæˆ‘åˆ é™¤äº†P6æ¨¡å‹é‡Œçš„Reorgæ“ä½œå…¶å®å°±è¯´FOcusï¼Œæ‰€ä»¥éœ€è¦é‡æ–°è®­ç»ƒï¼Œå¦‚æœä½ æƒ³ä½¿ç”¨V7åŸå§‹æƒé‡ï¼Œä½ åªéœ€è¦åœ¨YAMLé‡Œæ”¹å›å»

- 2022/7/7   ä¾æ—§å…¨ç½‘é¦–å‘ ï¼šä»¥ç›®å‰ä»“åº“çš„é­”æ”¹ç‰ˆV5ä¸ºåŸºå‡†åŒæ­¥äº†YOLOV7çš„æ ¸å¿ƒæ”¹åŠ¨ï¼Œä»£ç é£æ ¼æ˜¯æœ€æ–°çš„ï¼Œåç»­ä¼šæŒç»­å®Œå–„ä¼˜åŒ–ï¼Œå®Œç¾èåˆV7ï¼Œåç»­åšå®¢äº‰å–æ›´æ–°ç¬¬ä¸€æ—¶é—´ï¼

- 2022/5/23  åˆå¹¶æ›´æ–°äº†YOLOV5ä»“åº“çš„æœ€æ–°ç‰ˆæœ¬ï¼Œä½œè€…ä»£ç æœ‰ç‚¹å°é—®é¢˜å°±æ˜¯æ•°æ®é›†ä¼šé‡å¤ä¸‹è½½ï¼Œè¿™éƒ¨åˆ†æˆ‘æ²¡å°±æ²¡åˆå¹¶ä»–çš„æ›´æ–°ï¼Œå¼•å…¥äº†æ–°çš„ç®—å­ï¼Œçœ‹æ¥ä»–ä¹Ÿåœ¨æ¢ç´¢å®éªŒ

- 2022/3/26  æµ‹è¯•ä¸‹è§£è€¦è®­ç»ƒç»“æœ/æ›´æ–°GAMæ³¨æ„åŠ›å±‚ä»£ç ï¼šæŒ‰ç…§è®ºæ–‡ç¤ºæ„åœ¨å¤§æ¨¡å‹ä¸­ä½¿ç”¨åˆ†ç»„å·ç§¯é™ä½FLOPs,åŒæ­¥ç®€å•å®éªŒä¸‹ï¼Œå…³äºå®éªŒåœ¨é—²æš‡ä¹‹ä½™éƒ½ä¼šæ…¢æ…¢å®Œå–„çš„ã€‚
    ä»¥smallæ¨¡å‹ï¼Œåœ¨Visdroneæ•°æ®ä¸‹çš„ç®€å•éªŒè¯ï¼š
	|   Model     		 |   mAP@.5  | mAP@.5:95 | Parameters(M) | GFLOPs |
	| --------    		 |   ------  |  ------   | ------------- | ------ |
	| YOLOv5s     		 |   0.351    |  0.194   |     7.2       | 16.5   |
	| YOLOv5s+GAM 		 |   0.35    |  0.194    |     22.2      | 36.9   |
	| YOLOv5s_decoup     |   0.367   |  0.203    |     7.1       | 17.2   |
    | YOLOv5s_GAM_group   |  0.353  	|  0.192 	 |     11       | 21.4   |  ï¼ˆå¾…è¿›ä¸€æ­¥æ›´æ–°ï¼‰


- 2022/3/26  1.ä¿®å¤äº†ä¸€äº›å¸¸è§„çš„é—®é¢˜BUGå¹¶åˆå¹¶äº†V5ä½œè€…çš„æœ€æ–°ä»£ç æ›´æ–°ï¼Œå¤§æ¦‚åŒ…å«ä¹‹å‰ç¼ºå°‘äº†ä¸€äº›å¯å­¦ä¹ å‚æ•°å’Œä»£ç ä¼˜åŒ–,å¦‚æ·»åŠ äº†swintransformerV2.0çš„ç›¸å¯¹ä½ç½®ç¼–ç åŠ å…¥ä¼˜åŒ–å™¨ç­‰ã€‚ 2.ç›®å‰çœ‹æ¥GAMæ¢ç”¨ç»„å·ç§¯æ•ˆæœæœ‰å¾…å•†æ¦·ï¼Œåç»­è¿›ä¸€æ­¥æ•´ç†æ¶ˆèå®éªŒæ€»ç»“ã€‚
- 2022/3/16  å¯¹ä¸Šä¼ çš„GAMæ³¨æ„åŠ›å±‚è¿›è¡Œäº†ç®€å•çš„å®éªŒï¼Œyolov5s+GAMåœ¨Visdroneæ•°æ®é›†ä¸Šçš„ç»“æœä¸¾ä¾‹å‚è€ƒï¼Œåç»­çš„è¯å…¶å®éš¾ç‚¹åœ¨äºè½»é‡åŒ–ï¼Œæ¢ç©¶å¤§æ¨¡å‹çš„éª¨å¹²ä¼°è®¡åªæœ‰å¤§å‚ç ”ç©¶èµ„æºèƒ½æœ‰æˆæœ¬å»åšã€‚
- 2022/3/5   è¿‘æœŸä¼šæ•´ç†ä¸€äº›å»å¹´çš„å®éªŒæ•°æ®/ã€ä½¿ç”¨swin2çš„éª¨å¹²ï¼Œè¶…å‚æ•°éœ€è¦è°ƒè¯•ä¸€ä¸‹ï¼Œé¦–å…ˆè¦ç¨å¾®å‡ä½å­¦ä¹ ç‡ï¼Œï¼ˆå®æµ‹SGDï¼‰ï¼›ä¹Ÿå¯ä»¥æŠŠSWINå±‚ä½œä¸ºæ³¨æ„åŠ›æ’ä»¶è®­ç»ƒï¼Œè¿™ä¸ªå’Œä»¥å¾€çš„æ“ä½œç±»ä¼¼ï¼Œä¸å†èµ˜è¿°äº† éœ€è¦å¼€å¯--swin_float   å‘½ä»¤å‚æ•°ï¼Œå› ä¸ºç‚¹ç§¯ä¸è¢«cudaçš„halfæ”¯æŒï¼Œè€Œä¼˜åŒ–å™¨çš„é—®é¢˜ï¼Œé‚£ä¹ˆé—®é¢˜åŸºæœ¬å°±æ˜¯è¾ƒå¤šçš„swin block å †ç§¯å¯¼è‡´çš„å¢é‡æ›´æ–°ã€‚åŒæ—¶ä¼´éšç€GPUçš„å¼€é”€ã€‚ 
- 2022/3.1   ï¼ˆä¸å®Œæ•´æ›´æ–°,ä¾›å‚è€ƒï¼Œæ€•å¿™æ–­æ›´ï¼Œæ‰€ä»¥å…ˆæ”¾å‡ºéƒ¨åˆ†ä¿®æ”¹ï¼Œç›®å‰è¿˜åœ¨åŠ¨æ€è°ƒè¯•ä¸­ï¼‰æŒ‰ç…§SWintransformerV2.0 çš„æ”¹è¿›ç‚¹ï¼šä¿®æ”¹äº†NORMå±‚çš„ä½ç½®/attentionå°†dotæ¢æˆscaled cosine self-attentionï¼Œå¾…æ›´æ–°çš„ä¼˜åŒ–éƒ¨åˆ†ï¼š1.åºåˆ—çª—å£æ³¨æ„åŠ›è®¡ç®—ï¼Œé™ä½æ˜¾å­˜å¼€é”€ 2ã€è®­ç»ƒä¼˜åŒ–å™¨
- 2022/2.28  æ·»åŠ äº†ä¸€ä¸ªSwintransformerçš„Backboneå’Œyamlç¤ºæ„ç»“æ„ï¼Œå¾ˆå¤šäººæŠŠSWINè¿˜åƒä¹‹å‰åšæˆæ³¨æ„åŠ›å±‚ï¼Œä½†æ˜¯å…¶å®swinè®¾è®¡æ˜¯ä¸ºäº†æ‘’å¼ƒCNNå»å’ŒNLPä¸€ç»Ÿï¼Œè€Œä¸”ç²¾é«“åœ¨äºæ§åˆ¶è®¡ç®—å¤æ‚åº¦ï¼Œå…¶å®backboneçš„å…¨æ›¿æ¢ä¹Ÿè®¸æ›´å€¼å¾—å°è¯• ï¼Œå†…å­˜å¼€é”€å’Œç»“æ„è®¾è®¡å¾…ä¼˜åŒ–
- 2022/2.22  å¿™é‡ŒæŠ½é—²ï¼šæ›´æ–°äº†ä»Šå¤©çš„yolov5çš„å·¥ç¨‹ä¿®å¤ï¼Œä¿®æ”¹äº†è§£è€¦å¤´çš„ä»£ç é£æ ¼ï¼Œç›´æ¥yamlé€‰æ‹©å‚è€ƒä½¿ç”¨ï¼ŒæœåŠ¡å™¨å›æ»šäº†ä»£ç ã€‚SWINç®—å­åœ¨ï¼ŒYAMLæ–‡ä»¶ä¸¢å¤±äº†ï¼Œæ‰¾æ—¶é—´ä»æ–°å†™ä¸€ä¸ªå†ä¸Šä¼ ï¼Œå¤ªå¿™çœ‹æ›´æ–°å¯èƒ½ä¼˜å…ˆGITï¼Œç­‰æœ‰ç©ºåšå®¢ç»†è‡´å½’çº³ä¸‹
- 2022/2.6   ASFFä½¿ç”¨çš„BUGå·²ç»ä¿®å¤;è¿‘æœŸæ›´æ–°Swintransformerä»£ç ï¼Œç®€å•è¯´æ˜ä¸‹ç¨‹åºä¸Šå…¶å®æ˜¯ä¸¤ç§æ”¹æ³•ï¼š1.ç±»ä¼¼ç®—å­å±‚çš„ä¿®æ”¹ï¼Œè¿™ä¸ªæ¯”è¾ƒç®€å• 2ã€å…¨éƒ¨æ›¿æ¢æˆSwintransformerï¼Œè¿™ä¸ªå¯¹äºæ•´ä¸ªç¨‹åºå­˜åœ¨ä¸€å®šçš„ä»£ç ä¿®æ”¹åœ°æ–¹ï¼Œç¨å¾®å¤æ‚ç‚¹ã€‚
- 2022/1.9   è¡¥å……ä¸€äº›æ³¨æ„åŠ›ç®—å­GAMï¼ŒåŸç†åç»­CSDNè¯´æ˜ï¼Œä¿®å¤BUG
- 2021/11.3  åˆå¹¶æœ€æ–°çš„YOLOV5çš„æ”¹åŠ¨ï¼Œ æ›¿æ¢äº†CSPBOTTLENNECKçš„LeakRELUwä¸ºSLIUï¼Œå…¶ä½™å…¨æ˜¯ä»£ç å’Œå·¥ç¨‹è§„èŒƒä¿®æ”¹
- 2021.10.25 ä¿®å¤BUGï¼Œæ¢å¤EIOU
- 2021.10.13 æ›´æ–°åˆå¹¶YOLOV5v6.0ç‰ˆæœ¬ï¼Œæ”¹è¿›ç‚¹ï¼šç¬¬ä¸€æ—¶é—´çš„æ›´æ–°è§£æå¯å‚è€ƒ[CSNDåšå®¢](https://blog.csdn.net/weixin_44119362/article/details/120748319?spm=1001.2014.3001.5501)
- 2021.9.25  å°†è‡ªæ³¨æ„åŠ›ä½ç½®ç¼–ç è®¾ç½®æˆå¯é€‰é¡¹ï¼Œé»˜è®¤å–æ¶ˆï¼ŒCBAMä¸æ”¶æ•›â€”â€”å°†æ¿€æ´»å‡½æ•°æ”¹å›Sigmoid
- 2021.6.25  æ·»åŠ BIFPNç»“æ„åŒ…å«P5/P6å±‚ï¼Œå¢å¤§å¼€é”€ä½†æ˜¯å¯¹äºä¸€äº›ä»»åŠ¡æ˜¯èƒ½å¤Ÿæç‚¹çš„
- 2021.6     Botnet transformer ç®—å­å—å¼•å…¥äºBackboneåº•å±‚
- 2021.2.10  å…¨ç½‘é¦–å‘çš„YOLOV5é­”æ”¹ï¼ŒASFFæ£€æµ‹å¤´å°è£…åŠ å…¥ã€æ³¨æ„åŠ›æœºåˆ¶CBAMã€CooRDã€ç­‰æ³¨æ„åŠ›ç®—å­å¼•å…¥ï¼Œå¹¶ä»‹ç»äº†é€šç”¨ä¿®æ”¹æ–¹å¼


</details>

## <div align="center">é«˜æ€§èƒ½è§†é¢‘æ¨ç†éƒ¨ç½²â€”å¾…æ›´æ–°å‡çº§</div>
<details>
<summary>å·¥ç¨‹éƒ¨ç½² Why Deepstream?</summary>

å·¥ç¨‹éƒ¨ç½²ï¼šè¯¥ä»“åº“åªå±äºç ”ç©¶æ¢ç´¢ï¼Œä½†æ˜¯å·¥ç¨‹éƒ¨ç½²è®²ç©¶ç®€å•é«˜æ•ˆã€æ•…å¯ä»¥å‚è€ƒæˆ‘çš„Deepstream SDKæ”¹çš„é¡¹ç›®ï¼Œé›†åˆäº†é€šç”¨æ£€æµ‹ã€äººè„¸è¯†åˆ«ã€OCRä¸‰ä¸ªé¡¹ç›®ï¼Œé«˜æ€§èƒ½çš„éƒ¨ç½²AIæ¡†æ¶å¼€å‘é€»è¾‘ï¼Œè¿™ä¸ªé¡¹ç›®æ˜¯æˆ‘2021å¹´æ•´ç†å¹¶å¼€æºçš„ï¼Œä»£ç è¿˜æœªè§„èŒƒï¼Œä½†ç¨‹åºæ˜¯æ²¡é—®é¢˜çš„ã€‚
 DS_5.1&&Tensorrt7+ ï¼šhttps://github.com/positive666/Deepstream_Project

     1.è‹±ä¼Ÿè¾¾æä¾›çš„Deepstream &&Tensorrtï¼Œåº”ç”¨äºæµåª’ä½“å¤„ç†ï¼Œå› ä¸ºåšè¿‡ä¸šåŠ¡çš„éƒ½çŸ¥é“ï¼Œæ¨ç†æ€§èƒ½ä¸ç­‰äºç¨‹åºè¿è¡Œæ€§èƒ½ï¼Œæ ¸å¿ƒé™¤äº†æ¨¡å‹çš„æœ¬èº«å‰ªæé‡åŒ–ä¹‹å¤–ï¼Œæ¶‰åŠåˆ°äº†å¯¹æ•°æ®è¾“å…¥çš„å¤„ç†ï¼Œè¿™é‡Œçš„æ ¸å¿ƒé—®é¢˜æ˜¯å¦‚ä½•æé«˜GPUçš„åˆ©ç”¨ç‡ï¼Œé‚£ä¹ˆæœ€ç›´æ¥çš„å°±æ˜¯GPUç¼–è§£ç .
     2.ç›®å‰åµŒå…¥å¼éƒ¨ç½²å¯èƒ½å¤§å¤šé‡‡ç”¨å‰ªæé€šé“å‹ç¼©æ¨¡å‹çš„æµç¨‹ï¼Œåœ¨ç»“åˆä¸€äº›æ¡†æ¶å»è¿›è¡Œå¼•æ“æ¨ç†ï¼Œæ¨èYolov5nanoæˆ–è€…nanodetplus,(å·¥ç¨‹ä¸Šä¸»æµæ˜¯é€šé“è£å‰ªï¼Œæ›¿æ¢å¦‚C3çš„BOLOCKï¼Œä½ å¯ä»¥åœ¨ä»”ç»†æ¯”å¯¹YOLOV5çš„è¿­ä»£ã€‚è¿˜æœ‰å°±æ˜¯å¦‚ä½•ä½¿ç”¨SGDç‚¼ä¸¹çš„ç»éªŒäº†)
     è¿˜æœ‰å°±æ˜¯deepstreamçš„æ™®åŠï¼Œç½‘ä¸Šå¾ˆå¤šå‰ªæç‰ˆæœ¬æˆ‘ä¹Ÿçœ‹äº†å€¼å¾—å­¦ä¹ ï¼Œä½†æ˜¯å·¥ç¨‹ä¸åªåœ¨äºå­¦ä¹ ï¼Œè€Œåœ¨äºæˆæœ¬å’Œç»“æœã€‚
     3.x86å’ŒJestonéƒ½å¯ä»¥éƒ¨ç½²ï¼Œæ—¢æœ‰ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼Œæˆ‘è§‰å¾—å·¥ç¨‹å’Œç ”ç©¶åº”ç”¨æ˜¯å®Œå…¨ä¸åŒçš„æ“ä½œæ€è·¯ï¼Œç²¾ç®€é«˜æ•ˆè¾¾åˆ°ç›®çš„.deepstreamå…¨åšäº†å¹¶å®Œæˆé™ç»´æ‰“å‡» ï¼Œå½“ç„¶ä¹Ÿéœ€è¦ä¸€å®šçš„ç»¼åˆå¼€å‘èƒ½åŠ›ã€‚

</details>

## C++ sdkçš„å®Œæ•´Deepstream5.1éƒ¨ç½²ï¼ˆå†…ç½®C++åµŒå…¥çš„KafkaæœåŠ¡ï¼‰ 
  ç›®å‰æ˜¯5.1ç‰ˆæœ¬ï¼Œè¿‘æœŸæ›´æ–°6.0(ä¸»è¦åŒºåˆ«åœ¨äºTensorrt7å’ŒTensorrt8çš„æºç åŒºåˆ«å¯¼è‡´çš„ï¼Œéƒ¨åˆ†6.0 SDKæœ‰å˜åŠ¨)
  [Deepsteam YOLOV5 V5.0]https://github.com/positive666/Deepstream_Project/tree/main/Deepstream_Yolo 



## Acknowledgements

<details><summary> <b>Expand</b> </summary>

* [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
* [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)
* [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
* [https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose](https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose)
* [https://github.com/ChristophReich1996/Swin-Transformer-V2](https://github.com/ChristophReich1996/Swin-Transformer-V2)
* https://github.com/positive666/Deepstream_Project

</details>